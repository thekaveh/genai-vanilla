# ============================================
# GenAI Vanilla Stack - Environment Variables  
# ============================================
# Template configuration file - edit this file with your desired configuration
# The start.sh script automatically copies this to .env when needed
#
# ============================================
# COMMON SOURCE CONFIGURATIONS
# ============================================
# Edit the SOURCE variables below to configure your deployment:
#
# üè† LOCALHOST SETUP (using local Ollama + ComfyUI):
#    LLM_PROVIDER_SOURCE=ollama-localhost
#    COMFYUI_SOURCE=localhost
#    All other services will run in containers
#
# üê≥ FULL CONTAINER SETUP (everything in Docker):
#    LLM_PROVIDER_SOURCE=ollama-container-cpu
#    COMFYUI_SOURCE=container-cpu
#    All services run in containers (default)
#
# üöÄ GPU CONTAINER SETUP (for production):
#    LLM_PROVIDER_SOURCE=ollama-container-gpu
#    COMFYUI_SOURCE=container-gpu
#    GPU-accelerated services in containers
#
# üîë API SETUP (for cloud LLMs):
#    LLM_PROVIDER_SOURCE=api
#    Configure API providers in database with api_key
#
# ============================================
# Global Configuration
# ============================================
PROJECT_NAME=genai

# ============================================
# CORE INFRASTRUCTURE SERVICES
# ============================================

# --------------------------------------------
# Supabase Database (supabase-db)
# --------------------------------------------
SUPABASE_DB_SOURCE=container  # Options: container
SUPABASE_DB_IMAGE=supabase/postgres:17.4.1.016
SUPABASE_DB_PORT=63000
# IMPORTANT: Must be 'supabase_admin' - required by Supabase base image
SUPABASE_DB_USER=supabase_admin
SUPABASE_DB_PASSWORD=password
SUPABASE_DB_NAME=postgres
# Additional DB users for applications
SUPABASE_DB_APP_USER=app_user
SUPABASE_DB_APP_PASSWORD=app_password

# --------------------------------------------
# Redis Cache (redis)
# --------------------------------------------
REDIS_SOURCE=container  # Options: container
REDIS_IMAGE=redis:7.2-alpine
REDIS_PORT=63001
REDIS_PASSWORD=redis_password
REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0

# --------------------------------------------
# Supabase DB Init (supabase-db-init)
# --------------------------------------------
SUPABASE_DB_INIT_SOURCE=container  # Options: container, disabled (auto-managed by supabase-db)
SUPABASE_DB_INIT_IMAGE=postgres:15-alpine

# --------------------------------------------
# Supabase Meta (supabase-meta)
# --------------------------------------------
SUPABASE_META_SOURCE=container  # Options: container, disabled
SUPABASE_META_IMAGE=supabase/postgres-meta:v0.88.9
SUPABASE_META_PORT=63004

# --------------------------------------------
# Supabase Storage (supabase-storage)
# --------------------------------------------
SUPABASE_STORAGE_SOURCE=container  # Options: container, disabled
SUPABASE_STORAGE_IMAGE=supabase/storage-api:v1.22.7
SUPABASE_STORAGE_PORT=63005
STORAGE_REGION=local
STORAGE_FILE_SIZE_LIMIT=52428800
STORAGE_BACKEND=file
PROJECT_REF=default
TENANT_ID=stub

# --------------------------------------------
# Supabase Auth (supabase-auth)
# --------------------------------------------
SUPABASE_AUTH_SOURCE=container  # Options: container, disabled
SUPABASE_AUTH_IMAGE=supabase/gotrue:v2.171.0
SUPABASE_AUTH_PORT=63006
# IMPORTANT: Run ./generate_supabase_keys.sh to generate these securely
SUPABASE_JWT_SECRET=
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_KEY=

# --------------------------------------------
# Supabase API/PostgREST (supabase-api)
# --------------------------------------------
SUPABASE_API_SOURCE=container  # Options: container, disabled
SUPABASE_API_IMAGE=postgrest/postgrest:v12.2.10
SUPABASE_API_PORT=63007

# --------------------------------------------
# Supabase Realtime (supabase-realtime)
# --------------------------------------------
SUPABASE_REALTIME_SOURCE=container  # Options: container, disabled
SUPABASE_REALTIME_IMAGE=supabase/realtime:v2.33.72
SUPABASE_REALTIME_PORT=63008

# --------------------------------------------
# Neo4j Graph Database (neo4j-graph-db)
# --------------------------------------------
NEO4J_GRAPH_DB_SOURCE=container  # Options: container, localhost, disabled
NEO4J_GRAPH_DB_IMAGE=neo4j:5.19.0
GRAPH_DB_HOST=graph-db
GRAPH_DB_PORT=63010
GRAPH_DB_DASHBOARD_PORT=63011
GRAPH_DB_USER=neo4j
GRAPH_DB_PASSWORD=neo4j_password
GRAPH_DB_AUTH=neo4j/neo4j_password  # Neo4j format: username/password

# ============================================
# AI AND ML SERVICES
# ============================================

# --------------------------------------------
# LLM Provider Service (llm-provider)
# --------------------------------------------
# üè† For LOCALHOST SETUP: Set to 'ollama-localhost' to use local Ollama (port 11434)
# üê≥ For CONTAINER SETUP: Set to 'ollama-container-cpu' for Docker Ollama CPU (default)
# üöÄ For GPU SETUP: Set to 'ollama-container-gpu' for Docker Ollama with GPU acceleration
# üîë For API SETUP: Set to 'api' and configure API providers in database
LLM_PROVIDER_SOURCE=ollama-container-cpu  # Options: ollama-container-cpu, ollama-container-gpu, ollama-localhost, ollama-external, api, disabled
LLM_PROVIDER_IMAGE=ollama/ollama:latest
LLM_PROVIDER_PORT=63012
# For external providers (when SOURCE=external)
LLM_PROVIDER_EXTERNAL_URL=  # Required when SOURCE=external

# --------------------------------------------
# Ollama Model Puller (ollama-pull)
# --------------------------------------------
OLLAMA_PULL_SOURCE=container  # Options: container, disabled (auto-managed by llm-provider)
OLLAMA_PULL_IMAGE=alpine:latest

# --------------------------------------------
# Weaviate Vector Database (weaviate)
# --------------------------------------------
WEAVIATE_SOURCE=container  # Options: container, localhost, disabled
WEAVIATE_IMAGE=cr.weaviate.io/semitechnologies/weaviate:1.27.5
WEAVIATE_PORT=63019
WEAVIATE_GRPC_PORT=63020
WEAVIATE_INIT_SOURCE=container  # Options: container, disabled (auto-managed by weaviate)
WEAVIATE_INIT_IMAGE=alpine:latest
MULTI2VEC_CLIP_SOURCE=container-cpu  # Options: container-cpu, container-gpu, disabled
MULTI2VEC_CLIP_IMAGE=semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32
# Optional OpenAI API key for text2vec-openai module
OPENAI_API_KEY=

# --------------------------------------------
# ComfyUI Init (comfyui-init)
# --------------------------------------------
COMFYUI_INIT_SOURCE=container  # Options: container, disabled (auto-managed by comfyui)
COMFYUI_INIT_IMAGE=alpine:latest

# --------------------------------------------
# Local Deep Researcher (local-deep-researcher)
# --------------------------------------------
# NOTE: This is an adaptive service that automatically configures based on other services.
LOCAL_DEEP_RESEARCHER_SOURCE=container  # Options: container, disabled
LOCAL_DEEP_RESEARCHER_IMAGE=python:3.11-slim
LOCAL_DEEP_RESEARCHER_PORT=63013
LOCAL_DEEP_RESEARCHER_LOOPS=3
LOCAL_DEEP_RESEARCHER_SEARCH_API=searxng
LOCAL_DEEP_RESEARCHER_WORKERS=3

# --------------------------------------------
# SearxNG Search Engine (searxng)
# --------------------------------------------
SEARXNG_SOURCE=container  # Options: container, disabled
SEARXNG_IMAGE=searxng/searxng:latest
SEARXNG_PORT=63014
SEARXNG_SECRET=
SEARXNG_PUBLIC_INSTANCE=false
SEARXNG_ENABLE_METRICS=true
SEARXNG_DEFAULT_LOCALE=en

# --------------------------------------------
# n8n Workflow Automation (n8n)
# --------------------------------------------
N8N_SOURCE=container  # Options: container, disabled
N8N_IMAGE=n8nio/n8n:latest
N8N_PORT=63017
N8N_ENCRYPTION_KEY=your-random-encryption-key
N8N_AUTH_ENABLED=true
N8N_HOST=n8n.localhost
N8N_PROTOCOL=http
N8N_EXECUTIONS_MODE=queue
# Community packages support
N8N_COMMUNITY_PACKAGES_ENABLED=true
N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=true

# --------------------------------------------
# n8n Init Service (n8n-init)
# --------------------------------------------
N8N_INIT_SOURCE=container  # Options: container, disabled (auto-managed by n8n)
N8N_INIT_IMAGE=alpine:latest
N8N_INIT_NODES=n8n-nodes-comfyui,@ksc1234/n8n-nodes-comfyui-image-to-image,n8n-nodes-mcp

# --------------------------------------------
# ComfyUI Image Generation (comfyui)
# --------------------------------------------
# üè† For LOCALHOST SETUP: Set to 'localhost' to use local ComfyUI (port 8000 or 8188)
# üê≥ For CONTAINER SETUP: Set to 'container-cpu' for Docker ComfyUI CPU (default)
# üöÄ For GPU SETUP: Set to 'container-gpu' for Docker ComfyUI with GPU acceleration
COMFYUI_SOURCE=container-cpu  # Options: container-cpu, container-gpu, localhost, external, disabled
COMFYUI_IMAGE=ghcr.io/ai-dock/comfyui:v2-cpu-22.04-v0.2.7  # Use latest-cuda for GPU
COMFYUI_PORT=63018
COMFYUI_BASE_URL=http://comfyui:18188  # For localhost SOURCE: http://host.docker.internal:8000
COMFYUI_KONG_URL=http://kong-api-gateway:8000/comfyui
COMFYUI_ARGS=--listen
COMFYUI_AUTO_UPDATE=false
COMFYUI_PLATFORM=linux/amd64  # linux/amd64 for both CPU and GPU
# Storage Integration
COMFYUI_UPLOAD_TO_SUPABASE=true
COMFYUI_STORAGE_BUCKET=comfyui-images
# Model Management
COMFYUI_MODELS_PATH=/opt/ComfyUI/models
COMFYUI_OUTPUT_PATH=/opt/ComfyUI/output
COMFYUI_INPUT_PATH=/opt/ComfyUI/input
COMFYUI_CUSTOM_NODES_PATH=/opt/ComfyUI/custom_nodes
COMFYUI_LOCAL_MODELS_PATH=~/Documents/ComfyUI/models
# Model download configuration
COMFYUI_MODEL_SET=minimal  # Options: minimal (SD1.5 only), sd15 (SD1.5 + VAE), sdxl (SDXL + VAE), full (all models)

# ============================================
# APPLICATION SERVICES
# ============================================
# 
# NOTE: Some services in this section are "adaptive services" that automatically
# configure themselves based on other services (like LLM provider, ComfyUI, etc.).
# These adaptive services do not support SOURCE variations and always run as 
# containers when enabled. They include: backend, open-web-ui, local-deep-researcher.

# --------------------------------------------
# Supabase Studio (supabase-studio)
# --------------------------------------------
SUPABASE_STUDIO_SOURCE=container  # Options: container, disabled
SUPABASE_STUDIO_IMAGE=supabase/studio:latest
SUPABASE_STUDIO_PORT=63009

# --------------------------------------------
# Kong API Gateway (kong-api-gateway)
# --------------------------------------------
KONG_API_GATEWAY_SOURCE=container  # Options: container
KONG_API_GATEWAY_IMAGE=kong:3.9.0
KONG_HTTP_PORT=63002
KONG_HTTPS_PORT=63003
DASHBOARD_USERNAME=kong_admin
DASHBOARD_PASSWORD=kong_password

# --------------------------------------------
# Open WebUI (open-web-ui)
# --------------------------------------------
# NOTE: This is an adaptive service that automatically configures based on other services.
OPEN_WEB_UI_SOURCE=container  # Options: container, disabled
OPEN_WEB_UI_IMAGE=dyrnq/open-webui:latest
OPEN_WEB_UI_PORT=63015
OPEN_WEB_UI_SECRET_KEY=secret
# Redis WebSocket Integration
OPEN_WEB_UI_WEBSOCKET_SUPPORT=true
OPEN_WEB_UI_REDIS_DB=2
OPEN_WEB_UI_MODEL_CACHE_TTL=300

# --------------------------------------------
# Backend API Service (backend)
# --------------------------------------------
# NOTE: This is an adaptive service that automatically configures based on other services.
BACKEND_SOURCE=container  # Options: container, disabled
BACKEND_IMAGE=python:3.12
BACKEND_PORT=63016

# --------------------------------------------
# JupyterHub Data Science IDE (jupyterhub)
# --------------------------------------------
# NOTE: This is an adaptive service that automatically configures based on other services.
JUPYTERHUB_SOURCE=container  # Options: container, disabled
JUPYTERHUB_IMAGE=jupyter/datascience-notebook:latest
JUPYTERHUB_PORT=63048
JUPYTERHUB_TOKEN=  # Optional: Set token for authentication (empty = generate on start)

# ============================================
# GPU RESOURCE CONFIGURATION
# ============================================
# Resource limits for GPU-enabled services
PROD_ENV_CPUS=2
PROD_ENV_MEM_LIMIT=8g
PROD_ENV_BACKEND_CPUS=1
PROD_ENV_BACKEND_MEM_LIMIT=2g
PROD_ENV_N8N_CPUS=1
PROD_ENV_N8N_MEM_LIMIT=2g
PROD_ENV_COMFYUI_CPUS=2
PROD_ENV_COMFYUI_MEM_LIMIT=4g


